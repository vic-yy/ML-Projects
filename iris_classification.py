# -*- coding: utf-8 -*-
"""Iris-Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BI9WQrxf96KWk4tY8QHqe-CHGmD-ywOE
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

# 2. Carregar o dataset Iris
df = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')
df.head()

# 3. Análise Exploratória de Dados (EDA)
# Verificar número de exemplos por classe:
df['species'].value_counts()
# Estatísticas descritivas:
df.describe()
# Visualizar correlação entre variáveis:
sns.pairplot(df, hue='species')
plt.show()

"""### 🔍 1. **O que é um Pair Plot?**

* Cada célula da matriz representa a **relação entre duas variáveis** (ex: `sepal_length` vs `petal_length`).
* A diagonal mostra a **distribuição univariada** de cada variável (ex: histograma ou KDE para `petal_width`).
* Cada ponto é uma **amostra do conjunto Iris**, colorido pela sua **espécie**:

  * Azul = *Setosa*
  * Laranja = *Versicolor*
  * Verde = *Virginica*

---

### 📈 2. **Principais Insights dos Gráficos**

#### 🔹 **Separação clara: Setosa**

* As amostras da espécie **Setosa** (azul) formam um **grupo isolado**, especialmente nos pares envolvendo:

  * `petal_length`
  * `petal_width`
* Isso sugere que essas duas variáveis **separam muito bem a Setosa** das outras espécies.

#### 🔸 **Sobreposição: Versicolor e Virginica**

* As espécies **Versicolor** (laranja) e **Virginica** (verde) têm **alguma sobreposição**, especialmente em:

  * `sepal_length` vs `sepal_width`
* Ainda assim, variáveis como `petal_length` e `petal_width` ajudam a **diferenciá-las razoavelmente bem**.

#### 📊 **Distribuições na Diagonal**

* Os gráficos na diagonal mostram as **distribuições individuais** de cada variável.

  * `petal_length` e `petal_width` têm distribuições bem distintas entre as espécies.
  * `sepal_width` tem mais sobreposição entre as classes → menos útil isoladamente.

---

### ✅ Conclusões Rápidas

| Variável          | Boa para separar espécies? | Observações                    |
| ----------------- | -------------------------- | ------------------------------ |
| **petal\_length** | ✅ Excelente                | Separa bem todas               |
| **petal\_width**  | ✅ Excelente                | Especialmente útil para Setosa |
| **sepal\_length** | ⚠️ Moderada                | Um pouco de sobreposição       |
| **sepal\_width**  | ❌ Fraca                    | Muita sobreposição             |

---


"""

# 4. Pré-processamento dos dados
# Separar as variáveis independentes (X) e o alvo (y):
# df é o DataFrame com todas as colunas.

# A coluna 'species' é removida porque é o que queremos prever, não uma entrada.

# O parâmetro axis=1 indica que queremos remover uma coluna (não uma linha).

X = df.drop('species', axis=1)

# Cria o vetor de variável dependente (ou target), ou seja, a espécie da flor, que é o que o modelo precisa aprender a prever.


y = df['species']
# Dividir em dados de treino e teste:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""Claro! Vamos **explicar didaticamente, passo a passo** essa linha fundamental no processo de machine learning:

---

## 🔍 Linha de código:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

---

## 💡 Objetivo:

Dividir os dados em **dois conjuntos**:

* Um para **treinar** o modelo (`train`)
* Outro para **testar** (avaliar) o modelo (`test`)

---

## 🔠 Componentes da linha:

### 🟦 `train_test_split(X, y, ...)`

Essa função do `scikit-learn` pega os dados `X` (entradas) e `y` (rótulos), **embaralha** e **divide em duas partes**:

* Parte para treinamento
* Parte para teste

---

### 🔹 `X` = Dados de entrada (features)

Ex: comprimento e largura das pétalas e sépalas.

### 🔹 `y` = Rótulo de saída (target)

Ex: a espécie da flor (*Setosa*, *Versicolor*, *Virginica*).

---

## 🧩 Parâmetros da função:

### 🔸 `test_size=0.3`

* Quer dizer: **30% dos dados vão para o teste**
* Consequentemente, **70% dos dados vão para o treino**

### 🔸 `random_state=42`

* Define uma **semente aleatória fixa**, ou seja:
* Toda vez que rodar esse código, a divisão será **igual** (reprodutível)

---

## 📦 Retorno da função:

A função retorna **quatro conjuntos** separados:

| Variável  | Contém o quê?                                      |
| --------- | -------------------------------------------------- |
| `X_train` | 70% dos **dados de entrada** (usados para treinar) |
| `X_test`  | 30% dos dados de entrada (usados para testar)      |
| `y_train` | 70% dos **rótulos** correspondentes (espécies)     |
| `y_test`  | 30% dos rótulos (usados para avaliar o modelo)     |

---

## 📊 Ilustração

Imagine que temos 100 flores (linhas):

```
Antes da divisão:
X = [flores com 4 medidas]
y = [espécie de cada flor]

Depois da divisão:
X_train → 70 flores (medidas) → usado para ensinar
X_test  → 30 flores (medidas) → usado para testar
y_train → espécies das 70 flores
y_test  → espécies das 30 flores
```

---

## ✅ Por que fazer isso?

Se usássemos os **mesmos dados para treinar e testar**, o modelo poderia **memorizar** em vez de aprender a **generalizar**. Por isso, testamos com dados **nunca vistos** antes.

---


"""

# 5. Treinar o modelo
# Usando regressão logística:
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

"""## 🎯 Objetivo do Item 5:

Treinar um modelo de **Machine Learning** que **aprende a classificar** as espécies das flores com base em suas características.

O modelo que escolhemos é a **Regressão Logística**.

---

## ✅ Linha de código:

```python
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)
```

---

## 🤖 O que significa "treinar o modelo"?

Significa **ensinar o modelo** usando os dados de treino (`X_train` e `y_train`) para que ele **aprenda padrões** entre:

* As **medidas da flor** (comprimento e largura das pétalas e sépalas)
* E a **espécie da flor** (Setosa, Versicolor, Virginica)

---

## 🔁 Etapas desse processo:

### 1. `model = LogisticRegression(...)`

* Cria um modelo de **regressão logística** (explicada abaixo).
* `max_iter=200` define quantas vezes ele pode ajustar os pesos internamente para tentar melhorar.

### 2. `model.fit(X_train, y_train)`

* O `.fit()` é onde o **aprendizado realmente acontece**.
* O modelo:

  * Lê os exemplos em `X_train`
  * Compara com os rótulos reais em `y_train`
  * Ajusta internamente **pesos** para cada variável
  * Aprende uma **função de decisão** para prever a espécie com base nas medidas

---

## 🔎 Mas... o que é **Regressão**?

### 🔹 Regressão (simples ou linear):

É um método para **prever um número contínuo** com base em variáveis.

🧠 Exemplo:
Se quisermos prever a **altura de uma pessoa** com base na **idade**, a regressão linear tenta traçar uma reta:

```
altura = a * idade + b
```

---

## 🟠 E o que é **Regressão Logística**?

Apesar do nome “regressão”, ela é usada para **classificação**!
Serve para **prever categorias**, como:

> "Essa flor é da espécie Setosa, Versicolor ou Virginica?"

---

### 🎯 Como funciona a Regressão Logística:

1. **Pega as entradas (X)** e aplica uma **equação linear** (como na regressão comum):

   ```
   z = w1*x1 + w2*x2 + ... + b
   ```

2. Depois, passa esse valor por uma **função logística (sigmoide)** que "aperta" o resultado para algo entre **0 e 1**:

   ```
   probabilidade = 1 / (1 + e^(-z))
   ```

3. Essa probabilidade indica a **chance de pertencer a uma classe**.

4. Para mais de duas classes (como no Iris, que tem 3), usamos uma versão chamada **regressão logística multinomial** (com softmax).

---

## 🧪 Exemplo simples:

Imagine que o modelo analisa uma flor com:

```
petal_length = 1.4
petal_width = 0.2
```

A regressão logística vai calcular **a probabilidade de essa flor ser de cada espécie**, por exemplo:

| Espécie    | Probabilidade |
| ---------- | ------------- |
| Setosa     | 98%           |
| Versicolor | 1.5%          |
| Virginica  | 0.5%          |

O modelo **escolhe a espécie com maior probabilidade** (nesse caso: **Setosa**).

---

## 📌 Resumo Didático

| Conceito                        | Explicação Simples                                      |
| ------------------------------- | ------------------------------------------------------- |
| Regressão Linear                | Prediz **números contínuos** (ex: preço, altura, tempo) |
| Regressão Logística             | Prediz **categorias** (ex: sim/não, classe A/B/C)       |
| `.fit()`                        | Modelo **aprende** com os dados                         |
| Regressão Logística Multinomial | Permite classificar entre **várias classes**            |

---

"""

# 6. Fazer previsões
y_pred = model.predict(X_test)

"""
## 🧠 Objetivo:

Depois que o modelo foi treinado (no item 5), queremos **ver se ele aprendeu bem**. Para isso, fazemos previsões com ele.

---

## ✅ Linha de código:

```python
y_pred = model.predict(X_test)
```

---

## 🔎 Explicação passo a passo:

### 🔸 `model`

É o **modelo treinado**, que agora sabe "como" usar os dados de entrada para prever a espécie da flor.

### 🔸 `X_test`

É o conjunto de **dados de entrada (medidas)** que o modelo **nunca viu antes**.
Vamos usá-lo para **testar se o modelo generaliza bem**.

### 🔸 `model.predict(...)`

Esse comando diz:

> "Modelo, olhe essas flores (X\_test) e me diga de que espécie você acha que elas são."

Ele retorna um **vetor de previsões** (`y_pred`), que são as **espécies previstas** para cada flor.

---

## 🧪 Exemplo hipotético

Vamos supor que `X_test` tem 5 flores. O modelo então gera:

```python
y_pred = ['setosa', 'versicolor', 'setosa', 'virginica', 'virginica']
```

Esses são os **rótulos previstos** com base nas medidas de pétala e sépala.

---

## 🔄 E depois?

A gente compara esse `y_pred` com o `y_test` (as **respostas reais**) no **Item 7**, para avaliar **quantas o modelo acertou**.

---

## 🎓 Resumo Didático

| Elemento        | O que faz                                        |
| --------------- | ------------------------------------------------ |
| `X_test`        | Dados de entrada para teste (medidas das flores) |
| `model.predict` | Modelo prevê a classe de cada flor               |
| `y_pred`        | Vetor com as espécies previstas                  |
"""

# 7. Avaliar o modelo
print("Acurácia:", metrics.accuracy_score(y_test, y_pred))
print("Relatório de Classificação:\n", metrics.classification_report(y_test, y_pred))

conf_matrix = metrics.confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=df['species'].unique(), yticklabels=df['species'].unique())
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()

df

"""## 🔎 Explicação passo a passo:

### 1. 📊 `accuracy_score(y_test, y_pred)`

* Compara o que o modelo **previu** (`y_pred`) com os **rótulos reais** (`y_test`)
* Calcula a **porcentagem de acertos**:

📌 Fórmula:

```
acurácia = número de acertos / número total de previsões
```

🧠 Exemplo:
Se o modelo acertou 28 de 30 flores, a acurácia será:

```
28 / 30 = 0.933 → 93,3%
```

---

### 2. 📝 `classification_report(y_test, y_pred)`

Gera um **resumo detalhado** do desempenho do modelo para **cada espécie**, com:

| Métrica       | Significado Didático                                                          |
| ------------- | ----------------------------------------------------------------------------- |
| **Precision** | Das flores que o modelo disse serem daquela espécie, **quantas ele acertou?** |
| **Recall**    | Das flores que **realmente eram** daquela espécie, **quantas ele encontrou?** |
| **F1-score**  | Média ponderada entre precision e recall (equilíbrio)                         |
| **Support**   | Quantas flores reais existiam daquela espécie no teste                        |

---

### 3. 🔢 `confusion_matrix(y_test, y_pred)`

Gera a **matriz de confusão**: uma tabela que mostra:

|                      | **Previsto: Setosa** | **Versicolor** | **Virginica** |
| -------------------- | -------------------- | -------------- | ------------- |
| **Real: Setosa**     | ✅ Acertos            | ❌ Erros        | ❌ Erros       |
| **Real: Versicolor** | ❌ Erros              | ✅ Acertos      | ❌ Erros       |
| **Real: Virginica**  | ❌ Erros              | ❌ Erros        | ✅ Acertos     |

* O gráfico (heatmap) mostra **visualmente** onde o modelo acertou (diagonal) e errou (fora da diagonal).
* Cores mais fortes indicam mais amostras naquela célula.

---

## 📌 Resumo Didático

| Comando                        | O que mostra                                             |
| ------------------------------ | -------------------------------------------------------- |
| `accuracy_score()`             | Quantas previsões o modelo acertou, em média             |
| `classification_report()`      | Desempenho detalhado por espécie (precisão, recall, etc) |
| `confusion_matrix()` + heatmap | Onde o modelo acertou ou confundiu as espécies           |

"""