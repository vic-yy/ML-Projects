# -*- coding: utf-8 -*-
"""Iris-Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BI9WQrxf96KWk4tY8QHqe-CHGmD-ywOE
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

# 2. Carregar o dataset Iris
df = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')
df.head()

# 3. An√°lise Explorat√≥ria de Dados (EDA)
# Verificar n√∫mero de exemplos por classe:
df['species'].value_counts()
# Estat√≠sticas descritivas:
df.describe()
# Visualizar correla√ß√£o entre vari√°veis:
sns.pairplot(df, hue='species')
plt.show()

"""### üîç 1. **O que √© um Pair Plot?**

* Cada c√©lula da matriz representa a **rela√ß√£o entre duas vari√°veis** (ex: `sepal_length` vs `petal_length`).
* A diagonal mostra a **distribui√ß√£o univariada** de cada vari√°vel (ex: histograma ou KDE para `petal_width`).
* Cada ponto √© uma **amostra do conjunto Iris**, colorido pela sua **esp√©cie**:

  * Azul = *Setosa*
  * Laranja = *Versicolor*
  * Verde = *Virginica*

---

### üìà 2. **Principais Insights dos Gr√°ficos**

#### üîπ **Separa√ß√£o clara: Setosa**

* As amostras da esp√©cie **Setosa** (azul) formam um **grupo isolado**, especialmente nos pares envolvendo:

  * `petal_length`
  * `petal_width`
* Isso sugere que essas duas vari√°veis **separam muito bem a Setosa** das outras esp√©cies.

#### üî∏ **Sobreposi√ß√£o: Versicolor e Virginica**

* As esp√©cies **Versicolor** (laranja) e **Virginica** (verde) t√™m **alguma sobreposi√ß√£o**, especialmente em:

  * `sepal_length` vs `sepal_width`
* Ainda assim, vari√°veis como `petal_length` e `petal_width` ajudam a **diferenci√°-las razoavelmente bem**.

#### üìä **Distribui√ß√µes na Diagonal**

* Os gr√°ficos na diagonal mostram as **distribui√ß√µes individuais** de cada vari√°vel.

  * `petal_length` e `petal_width` t√™m distribui√ß√µes bem distintas entre as esp√©cies.
  * `sepal_width` tem mais sobreposi√ß√£o entre as classes ‚Üí menos √∫til isoladamente.

---

### ‚úÖ Conclus√µes R√°pidas

| Vari√°vel          | Boa para separar esp√©cies? | Observa√ß√µes                    |
| ----------------- | -------------------------- | ------------------------------ |
| **petal\_length** | ‚úÖ Excelente                | Separa bem todas               |
| **petal\_width**  | ‚úÖ Excelente                | Especialmente √∫til para Setosa |
| **sepal\_length** | ‚ö†Ô∏è Moderada                | Um pouco de sobreposi√ß√£o       |
| **sepal\_width**  | ‚ùå Fraca                    | Muita sobreposi√ß√£o             |

---


"""

# 4. Pr√©-processamento dos dados
# Separar as vari√°veis independentes (X) e o alvo (y):
# df √© o DataFrame com todas as colunas.

# A coluna 'species' √© removida porque √© o que queremos prever, n√£o uma entrada.

# O par√¢metro axis=1 indica que queremos remover uma coluna (n√£o uma linha).

X = df.drop('species', axis=1)

# Cria o vetor de vari√°vel dependente (ou target), ou seja, a esp√©cie da flor, que √© o que o modelo precisa aprender a prever.


y = df['species']
# Dividir em dados de treino e teste:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""Claro! Vamos **explicar didaticamente, passo a passo** essa linha fundamental no processo de machine learning:

---

## üîç Linha de c√≥digo:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

---

## üí° Objetivo:

Dividir os dados em **dois conjuntos**:

* Um para **treinar** o modelo (`train`)
* Outro para **testar** (avaliar) o modelo (`test`)

---

## üî† Componentes da linha:

### üü¶ `train_test_split(X, y, ...)`

Essa fun√ß√£o do `scikit-learn` pega os dados `X` (entradas) e `y` (r√≥tulos), **embaralha** e **divide em duas partes**:

* Parte para treinamento
* Parte para teste

---

### üîπ `X` = Dados de entrada (features)

Ex: comprimento e largura das p√©talas e s√©palas.

### üîπ `y` = R√≥tulo de sa√≠da (target)

Ex: a esp√©cie da flor (*Setosa*, *Versicolor*, *Virginica*).

---

## üß© Par√¢metros da fun√ß√£o:

### üî∏ `test_size=0.3`

* Quer dizer: **30% dos dados v√£o para o teste**
* Consequentemente, **70% dos dados v√£o para o treino**

### üî∏ `random_state=42`

* Define uma **semente aleat√≥ria fixa**, ou seja:
* Toda vez que rodar esse c√≥digo, a divis√£o ser√° **igual** (reprodut√≠vel)

---

## üì¶ Retorno da fun√ß√£o:

A fun√ß√£o retorna **quatro conjuntos** separados:

| Vari√°vel  | Cont√©m o qu√™?                                      |
| --------- | -------------------------------------------------- |
| `X_train` | 70% dos **dados de entrada** (usados para treinar) |
| `X_test`  | 30% dos dados de entrada (usados para testar)      |
| `y_train` | 70% dos **r√≥tulos** correspondentes (esp√©cies)     |
| `y_test`  | 30% dos r√≥tulos (usados para avaliar o modelo)     |

---

## üìä Ilustra√ß√£o

Imagine que temos 100 flores (linhas):

```
Antes da divis√£o:
X = [flores com 4 medidas]
y = [esp√©cie de cada flor]

Depois da divis√£o:
X_train ‚Üí 70 flores (medidas) ‚Üí usado para ensinar
X_test  ‚Üí 30 flores (medidas) ‚Üí usado para testar
y_train ‚Üí esp√©cies das 70 flores
y_test  ‚Üí esp√©cies das 30 flores
```

---

## ‚úÖ Por que fazer isso?

Se us√°ssemos os **mesmos dados para treinar e testar**, o modelo poderia **memorizar** em vez de aprender a **generalizar**. Por isso, testamos com dados **nunca vistos** antes.

---


"""

# 5. Treinar o modelo
# Usando regress√£o log√≠stica:
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

"""## üéØ Objetivo do Item 5:

Treinar um modelo de **Machine Learning** que **aprende a classificar** as esp√©cies das flores com base em suas caracter√≠sticas.

O modelo que escolhemos √© a **Regress√£o Log√≠stica**.

---

## ‚úÖ Linha de c√≥digo:

```python
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)
```

---

## ü§ñ O que significa "treinar o modelo"?

Significa **ensinar o modelo** usando os dados de treino (`X_train` e `y_train`) para que ele **aprenda padr√µes** entre:

* As **medidas da flor** (comprimento e largura das p√©talas e s√©palas)
* E a **esp√©cie da flor** (Setosa, Versicolor, Virginica)

---

## üîÅ Etapas desse processo:

### 1. `model = LogisticRegression(...)`

* Cria um modelo de **regress√£o log√≠stica** (explicada abaixo).
* `max_iter=200` define quantas vezes ele pode ajustar os pesos internamente para tentar melhorar.

### 2. `model.fit(X_train, y_train)`

* O `.fit()` √© onde o **aprendizado realmente acontece**.
* O modelo:

  * L√™ os exemplos em `X_train`
  * Compara com os r√≥tulos reais em `y_train`
  * Ajusta internamente **pesos** para cada vari√°vel
  * Aprende uma **fun√ß√£o de decis√£o** para prever a esp√©cie com base nas medidas

---

## üîé Mas... o que √© **Regress√£o**?

### üîπ Regress√£o (simples ou linear):

√â um m√©todo para **prever um n√∫mero cont√≠nuo** com base em vari√°veis.

üß† Exemplo:
Se quisermos prever a **altura de uma pessoa** com base na **idade**, a regress√£o linear tenta tra√ßar uma reta:

```
altura = a * idade + b
```

---

## üü† E o que √© **Regress√£o Log√≠stica**?

Apesar do nome ‚Äúregress√£o‚Äù, ela √© usada para **classifica√ß√£o**!
Serve para **prever categorias**, como:

> "Essa flor √© da esp√©cie Setosa, Versicolor ou Virginica?"

---

### üéØ Como funciona a Regress√£o Log√≠stica:

1. **Pega as entradas (X)** e aplica uma **equa√ß√£o linear** (como na regress√£o comum):

   ```
   z = w1*x1 + w2*x2 + ... + b
   ```

2. Depois, passa esse valor por uma **fun√ß√£o log√≠stica (sigmoide)** que "aperta" o resultado para algo entre **0 e 1**:

   ```
   probabilidade = 1 / (1 + e^(-z))
   ```

3. Essa probabilidade indica a **chance de pertencer a uma classe**.

4. Para mais de duas classes (como no Iris, que tem 3), usamos uma vers√£o chamada **regress√£o log√≠stica multinomial** (com softmax).

---

## üß™ Exemplo simples:

Imagine que o modelo analisa uma flor com:

```
petal_length = 1.4
petal_width = 0.2
```

A regress√£o log√≠stica vai calcular **a probabilidade de essa flor ser de cada esp√©cie**, por exemplo:

| Esp√©cie    | Probabilidade |
| ---------- | ------------- |
| Setosa     | 98%           |
| Versicolor | 1.5%          |
| Virginica  | 0.5%          |

O modelo **escolhe a esp√©cie com maior probabilidade** (nesse caso: **Setosa**).

---

## üìå Resumo Did√°tico

| Conceito                        | Explica√ß√£o Simples                                      |
| ------------------------------- | ------------------------------------------------------- |
| Regress√£o Linear                | Prediz **n√∫meros cont√≠nuos** (ex: pre√ßo, altura, tempo) |
| Regress√£o Log√≠stica             | Prediz **categorias** (ex: sim/n√£o, classe A/B/C)       |
| `.fit()`                        | Modelo **aprende** com os dados                         |
| Regress√£o Log√≠stica Multinomial | Permite classificar entre **v√°rias classes**            |

---

"""

# 6. Fazer previs√µes
y_pred = model.predict(X_test)

"""
## üß† Objetivo:

Depois que o modelo foi treinado (no item 5), queremos **ver se ele aprendeu bem**. Para isso, fazemos previs√µes com ele.

---

## ‚úÖ Linha de c√≥digo:

```python
y_pred = model.predict(X_test)
```

---

## üîé Explica√ß√£o passo a passo:

### üî∏ `model`

√â o **modelo treinado**, que agora sabe "como" usar os dados de entrada para prever a esp√©cie da flor.

### üî∏ `X_test`

√â o conjunto de **dados de entrada (medidas)** que o modelo **nunca viu antes**.
Vamos us√°-lo para **testar se o modelo generaliza bem**.

### üî∏ `model.predict(...)`

Esse comando diz:

> "Modelo, olhe essas flores (X\_test) e me diga de que esp√©cie voc√™ acha que elas s√£o."

Ele retorna um **vetor de previs√µes** (`y_pred`), que s√£o as **esp√©cies previstas** para cada flor.

---

## üß™ Exemplo hipot√©tico

Vamos supor que `X_test` tem 5 flores. O modelo ent√£o gera:

```python
y_pred = ['setosa', 'versicolor', 'setosa', 'virginica', 'virginica']
```

Esses s√£o os **r√≥tulos previstos** com base nas medidas de p√©tala e s√©pala.

---

## üîÑ E depois?

A gente compara esse `y_pred` com o `y_test` (as **respostas reais**) no **Item 7**, para avaliar **quantas o modelo acertou**.

---

## üéì Resumo Did√°tico

| Elemento        | O que faz                                        |
| --------------- | ------------------------------------------------ |
| `X_test`        | Dados de entrada para teste (medidas das flores) |
| `model.predict` | Modelo prev√™ a classe de cada flor               |
| `y_pred`        | Vetor com as esp√©cies previstas                  |
"""

# 7. Avaliar o modelo
print("Acur√°cia:", metrics.accuracy_score(y_test, y_pred))
print("Relat√≥rio de Classifica√ß√£o:\n", metrics.classification_report(y_test, y_pred))

conf_matrix = metrics.confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=df['species'].unique(), yticklabels=df['species'].unique())
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o')
plt.show()

df

"""## üîé Explica√ß√£o passo a passo:

### 1. üìä `accuracy_score(y_test, y_pred)`

* Compara o que o modelo **previu** (`y_pred`) com os **r√≥tulos reais** (`y_test`)
* Calcula a **porcentagem de acertos**:

üìå F√≥rmula:

```
acur√°cia = n√∫mero de acertos / n√∫mero total de previs√µes
```

üß† Exemplo:
Se o modelo acertou 28 de 30 flores, a acur√°cia ser√°:

```
28 / 30 = 0.933 ‚Üí 93,3%
```

---

### 2. üìù `classification_report(y_test, y_pred)`

Gera um **resumo detalhado** do desempenho do modelo para **cada esp√©cie**, com:

| M√©trica       | Significado Did√°tico                                                          |
| ------------- | ----------------------------------------------------------------------------- |
| **Precision** | Das flores que o modelo disse serem daquela esp√©cie, **quantas ele acertou?** |
| **Recall**    | Das flores que **realmente eram** daquela esp√©cie, **quantas ele encontrou?** |
| **F1-score**  | M√©dia ponderada entre precision e recall (equil√≠brio)                         |
| **Support**   | Quantas flores reais existiam daquela esp√©cie no teste                        |

---

### 3. üî¢ `confusion_matrix(y_test, y_pred)`

Gera a **matriz de confus√£o**: uma tabela que mostra:

|                      | **Previsto: Setosa** | **Versicolor** | **Virginica** |
| -------------------- | -------------------- | -------------- | ------------- |
| **Real: Setosa**     | ‚úÖ Acertos            | ‚ùå Erros        | ‚ùå Erros       |
| **Real: Versicolor** | ‚ùå Erros              | ‚úÖ Acertos      | ‚ùå Erros       |
| **Real: Virginica**  | ‚ùå Erros              | ‚ùå Erros        | ‚úÖ Acertos     |

* O gr√°fico (heatmap) mostra **visualmente** onde o modelo acertou (diagonal) e errou (fora da diagonal).
* Cores mais fortes indicam mais amostras naquela c√©lula.

---

## üìå Resumo Did√°tico

| Comando                        | O que mostra                                             |
| ------------------------------ | -------------------------------------------------------- |
| `accuracy_score()`             | Quantas previs√µes o modelo acertou, em m√©dia             |
| `classification_report()`      | Desempenho detalhado por esp√©cie (precis√£o, recall, etc) |
| `confusion_matrix()` + heatmap | Onde o modelo acertou ou confundiu as esp√©cies           |

"""